#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Seoul Market Risk ML Training Pipeline
ëª©í‘œ: ë¡œê·¸ ë³€í™˜ëœ íƒ€ê²Ÿìœ¼ë¡œ MAE ëŒ€í­ ê°ì†Œ
"""

import pandas as pd
import numpy as np
import joblib
import json
import os
from datetime import datetime
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

class EnhancedMarketRiskTrainer:
    def __init__(self):
        """í–¥ìƒëœ ëª¨ë¸ í›ˆë ¨ê¸° ì´ˆê¸°í™”"""
        self.models = {}
        self.results = {}
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    def load_preprocessed_data(self):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“¥ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”©...")

        try:
            X = joblib.load('data/processed/X_enhanced.joblib')
            y = joblib.load('data/processed/y_enhanced.joblib')
            features = joblib.load('data/processed/features_enhanced.joblib')

            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(X):,} ìƒ˜í”Œ, {len(features)} í”¼ì²˜")
            return X, y, features

        except FileNotFoundError:
            print("âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. enhanced_preprocessing.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            raise

    def create_models(self):
        """í–¥ìƒëœ ëª¨ë¸ ì„¤ì •"""
        print("ğŸ¤– ëª¨ë¸ ì„¤ì •...")

        self.models = {
            'enhanced_randomforest': RandomForestRegressor(
                n_estimators=200,
                max_depth=15,
                min_samples_split=10,
                min_samples_leaf=5,
                random_state=42,
                n_jobs=-1
            ),
            'enhanced_gradient_boosting': GradientBoostingRegressor(
                n_estimators=200,
                max_depth=8,
                learning_rate=0.1,
                min_samples_split=10,
                min_samples_leaf=5,
                random_state=42
            ),
            'regularized_linear': Ridge(
                alpha=100.0,
                random_state=42
            )
        }

        print(f"  ìƒì„±ëœ ëª¨ë¸ ìˆ˜: {len(self.models)}")

    def train_and_evaluate_model(self, model_name, model, X_train, X_test, y_train, y_test):
        """ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€"""
        print(f"ğŸ¯ {model_name} í›ˆë ¨ ì¤‘...")

        # ëª¨ë¸ í›ˆë ¨
        model.fit(X_train, y_train)

        # ì˜ˆì¸¡
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)

        # ë¡œê·¸ ê³µê°„ì—ì„œì˜ ë©”íŠ¸ë¦­
        train_mae_log = mean_absolute_error(y_train, y_train_pred)
        test_mae_log = mean_absolute_error(y_test, y_test_pred)
        test_r2_log = r2_score(y_test, y_test_pred)

        # ì›ë³¸ ê³µê°„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹¤ì œ MAE ê³„ì‚°
        y_train_orig = np.expm1(y_train)
        y_test_orig = np.expm1(y_test)
        y_train_pred_orig = np.expm1(y_train_pred)
        y_test_pred_orig = np.expm1(y_test_pred)

        train_mae_orig = mean_absolute_error(y_train_orig, y_train_pred_orig)
        test_mae_orig = mean_absolute_error(y_test_orig, y_test_pred_orig)
        test_r2_orig = r2_score(y_test_orig, y_test_pred_orig)

        # êµì°¨ ê²€ì¦ (ë¡œê·¸ ê³µê°„ì—ì„œ)
        cv_scores = cross_val_score(model, X_train, y_train,
                                   cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)
        cv_mae = -cv_scores.mean()
        cv_std = cv_scores.std()

        results = {
            'model_name': model_name,
            'log_space_metrics': {
                'train_mae': train_mae_log,
                'test_mae': test_mae_log,
                'test_r2': test_r2_log,
                'cv_mae_mean': cv_mae,
                'cv_mae_std': cv_std
            },
            'original_space_metrics': {
                'train_mae': train_mae_orig,
                'test_mae': test_mae_orig,
                'test_r2': test_r2_orig
            }
        }

        # ëª¨ë¸ ì €ì¥
        model_path = f'models/enhanced_{model_name}_{self.timestamp}.joblib'
        joblib.dump(model, model_path)
        results['model_path'] = model_path

        print(f"  ì›ë³¸ê³µê°„ MAE: {test_mae_orig:,.0f}ì›")
        print(f"  ì›ë³¸ê³µê°„ RÂ²: {test_r2_orig:.3f}")
        print(f"  ë¡œê·¸ê³µê°„ MAE: {test_mae_log:.3f}")

        return results

    def compare_models(self):
        """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ...")

        comparison = []
        for model_name, result in self.results.items():
            comparison.append({
                'model': model_name,
                'original_mae': result['original_space_metrics']['test_mae'],
                'original_r2': result['original_space_metrics']['test_r2'],
                'log_mae': result['log_space_metrics']['test_mae'],
                'log_r2': result['log_space_metrics']['test_r2']
            })

        # ì›ë³¸ ê³µê°„ MAE ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        comparison.sort(key=lambda x: x['original_mae'])

        print("\nğŸ† ëª¨ë¸ ìˆœìœ„ (ì›ë³¸ê³µê°„ MAE ê¸°ì¤€):")
        for i, comp in enumerate(comparison, 1):
            print(f"  {i}. {comp['model']}")
            print(f"     ì›ë³¸ MAE: {comp['original_mae']:,.0f}ì›")
            print(f"     ì›ë³¸ RÂ²: {comp['original_r2']:.3f}")
            print(f"     ë¡œê·¸ MAE: {comp['log_mae']:.3f}")
            print()

        return comparison

    def save_results(self, comparison):
        """ê²°ê³¼ ì €ì¥"""
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥...")

        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('training_results', exist_ok=True)

        # ìƒì„¸ ê²°ê³¼ ì €ì¥
        detailed_results = {
            'timestamp': self.timestamp,
            'enhanced_preprocessing': True,
            'log_transformation': True,
            'geographic_clustering': True,
            'models_trained': list(self.results.keys()),
            'detailed_results': self.results,
            'performance_comparison': comparison,
            'best_model': comparison[0]['model'],
            'improvement_notes': {
                'target_transformation': 'log1p applied to reduce skewness',
                'geographic_features': '6-tier Seoul district clustering',
                'feature_engineering': 'time patterns, demographics, relative performance',
                'data_utilization': 'All available years (2020-2024) combined'
            }
        }

        # JSON ì €ì¥
        result_file = f'training_results/enhanced_training_results_{self.timestamp}.json'
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2, default=str)

        # ê°„ë‹¨í•œ ìš”ì•½ ì €ì¥
        summary_file = f'training_results/enhanced_summary_{self.timestamp}.txt'
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("ğŸ¯ Enhanced Seoul Market Risk ML Training Results\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Data Improvements Applied: âœ…\n")
            f.write(f"  - Log transformation: âœ…\n")
            f.write(f"  - Geographic clustering: âœ… (6 tiers)\n")
            f.write(f"  - Enhanced features: âœ…\n")
            f.write(f"  - Maximum data usage: âœ…\n\n")

            f.write("ğŸ† Model Performance (Original Space):\n")
            for i, comp in enumerate(comparison, 1):
                f.write(f"{i}. {comp['model']}\n")
                f.write(f"   MAE: {comp['original_mae']:,.0f}ì›\n")
                f.write(f"   RÂ²: {comp['original_r2']:.3f}\n\n")

            f.write(f"ğŸ’¡ Best Model: {comparison[0]['model']}\n")
            f.write(f"ğŸ¯ Target MAE (500K): {'âœ… ë‹¬ì„±' if comparison[0]['original_mae'] <= 500000 else 'âŒ ë¯¸ë‹¬ì„±'}\n")

        print(f"âœ… ìƒì„¸ê²°ê³¼: {result_file}")
        print(f"âœ… ìš”ì•½: {summary_file}")

    def run_training_pipeline(self):
        """ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ Enhanced Training Pipeline ì‹œì‘...")
        print("=" * 60)

        # 1. ë°ì´í„° ë¡œë“œ
        X, y, features = self.load_preprocessed_data()

        # 2. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
        print("ğŸ”„ ë°ì´í„° ë¶„í• ...")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=None
        )
        print(f"  í›ˆë ¨: {len(X_train):,}, í…ŒìŠ¤íŠ¸: {len(X_test):,}")

        # 3. ëª¨ë¸ ìƒì„±
        self.create_models()

        # 4. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        print("\nğŸ¯ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        for model_name, model in self.models.items():
            result = self.train_and_evaluate_model(
                model_name, model, X_train, X_test, y_train, y_test
            )
            self.results[model_name] = result

        # 5. ì„±ëŠ¥ ë¹„êµ
        print("\n" + "=" * 60)
        comparison = self.compare_models()

        # 6. ê²°ê³¼ ì €ì¥
        self.save_results(comparison)

        print("=" * 60)
        print("âœ… Enhanced Training ì™„ë£Œ!")

        # ê°œì„  íš¨ê³¼ ì¶œë ¥
        best_mae = comparison[0]['original_mae']
        target_mae = 500000
        previous_mae = 33785880  # ì´ì „ ê²°ê³¼

        print(f"\nğŸ“ˆ ê°œì„  íš¨ê³¼:")
        print(f"  ì´ì „ MAE: {previous_mae:,.0f}ì›")
        print(f"  í˜„ì¬ MAE: {best_mae:,.0f}ì›")
        print(f"  ê°œì„ ìœ¨: {((previous_mae - best_mae) / previous_mae * 100):.1f}%")
        print(f"  ëª©í‘œ ë‹¬ì„±: {'âœ…' if best_mae <= target_mae else 'âŒ'}")

        return comparison

if __name__ == "__main__":
    # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('data/processed', exist_ok=True)
    os.makedirs('models', exist_ok=True)

    # í›ˆë ¨ ì‹¤í–‰
    trainer = EnhancedMarketRiskTrainer()
    results = trainer.run_training_pipeline()

    print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"  1. ê²°ê³¼ í™•ì¸: training_results/ í´ë”")
    print(f"  2. ìµœì  ëª¨ë¸: models/ í´ë”")
    print(f"  3. ì¶”ê°€ íŠœë‹ì´ í•„ìš”í•˜ë©´ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •")