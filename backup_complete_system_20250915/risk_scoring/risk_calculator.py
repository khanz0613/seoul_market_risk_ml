"""
Risk Score Calculator for Seoul Market Risk ML System
Real-time business risk assessment with 5-level classification and explainability.
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any, Union
import logging
from pathlib import Path
from datetime import datetime, timedelta
import json
import warnings
from dataclasses import dataclass, field
from enum import Enum
import math
warnings.filterwarnings('ignore')

# ML libraries for explainability
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    warnings.warn("SHAP not available - explanations will be simplified")

from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Internal imports
from ..utils.config_loader import load_config, get_data_paths
from ..feature_engineering.feature_engine import SeoulFeatureEngine
from ..models.model_orchestrator import SeoulModelOrchestrator, PredictionRequest

logger = logging.getLogger(__name__)


class OpportunityLevel(Enum):
    """Financial opportunity level classifications."""
    VERY_HIGH_RISK = (1, "ë§¤ìš°ìœ„í—˜", "Very High Risk", "#FF0000")     # 0-20 points
    HIGH_RISK = (2, "ìœ„í—˜êµ°", "High Risk", "#FF6600")              # 21-40 points  
    MODERATE = (3, "ì ì •", "Moderate", "#FFAA00")                 # 41-60 points
    GOOD = (4, "ì¢‹ìŒ", "Good", "#66BB00")                        # 61-80 points
    VERY_GOOD = (5, "ë§¤ìš°ì¢‹ìŒ", "Very Good", "#00AA00")            # 81-100 points
    
    def __init__(self, level: int, korean: str, english: str, color: str):
        self.level = level
        self.korean = korean  
        self.english = english
        self.color = color


@dataclass
class RiskComponent:
    """Individual risk component with score and contribution."""
    name: str
    korean_name: str
    score: float
    weight: float
    contribution: float
    percentile: float
    status: str
    explanation: str


@dataclass 
class OpportunityAssessment:
    """Complete opportunity assessment result."""
    business_id: str
    opportunity_score: float
    opportunity_level: OpportunityLevel
    confidence_score: float
    assessment_timestamp: str
    
    # Financial service recommendations
    recommended_action: str  # "loan", "investment", "monitoring"
    loan_necessity: float    # How much loan needed (0 if not needed)
    investment_potential: float  # Investment suitability score (0-100)
    
    # Component analysis
    components: List[RiskComponent]
    component_scores: Dict[str, float]
    
    # Predictions and trends
    revenue_forecast: Optional[pd.DataFrame] = None
    trend_analysis: Optional[Dict[str, Any]] = None
    
    # Explanations and recommendations
    key_opportunity_factors: List[str] = field(default_factory=list)
    stability_factors: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    
    # SHAP explanations (if available)
    shap_values: Optional[Dict[str, float]] = None
    feature_importance: Optional[Dict[str, float]] = None


class SeoulOpportunityScoreCalculator:
    """
    Proactive Financial Opportunity Calculator for Seoul Market Risk ML System.
    
    Implements opportunity-based scoring for proactive financial services:
    - ë§¤ì¶œë³€í™”ìœ¨ (30%): Revenue growth patterns and stability
    - ë³€ë™ì„± (20%): Revenue volatility as risk/opportunity indicator
    - íŠ¸ë Œë“œ (20%): Growth trend strength and sustainability
    - ê³„ì ˆì„±ì´íƒˆ (15%): Seasonal predictability and management
    - ì—…ì¢…ë¹„êµ (15%): Competitive positioning and industry performance
    
    Score interpretation:
    - 0-20ì  (ë§¤ìš°ìœ„í—˜): ì„ ì œì  ê¸´ê¸‰ëŒ€ì¶œ í•„ìš”
    - 21-40ì  (ìœ„í—˜êµ°): ì•ˆì •í™” ëŒ€ì¶œ ì¶”ì²œ
    - 41-60ì  (ì ì •): ëª¨ë‹ˆí„°ë§ ì§€ì†
    - 61-80ì  (ì¢‹ìŒ): ì„±ì¥íˆ¬ì ê¸°íšŒ
    - 81-100ì  (ë§¤ìš°ì¢‹ìŒ): ê³ ìˆ˜ìµ íˆ¬ì ì¶”ì²œ
    """
    
    def __init__(self, feature_engine: Optional[SeoulFeatureEngine] = None,
                 model_orchestrator: Optional[SeoulModelOrchestrator] = None,
                 config_path: Optional[str] = None):
        
        self.config = load_config(config_path)
        self.risk_config = self.config['risk_scoring']
        self.data_paths = get_data_paths(self.config)
        
        # Core engines
        self.feature_engine = feature_engine or SeoulFeatureEngine()
        self.model_orchestrator = model_orchestrator
        
        # Risk scoring weights (from handover report)
        self.component_weights = {
            'revenue_change': 0.30,      # ë§¤ì¶œë³€í™”ìœ¨
            'volatility': 0.20,          # ë³€ë™ì„±  
            'trend': 0.20,               # íŠ¸ë Œë“œ
            'seasonality_deviation': 0.15, # ê³„ì ˆì„±ì´íƒˆ
            'industry_comparison': 0.15   # ì—…ì¢…ë¹„êµ
        }
        
        # Opportunity level thresholds
        self.opportunity_thresholds = {
            OpportunityLevel.VERY_HIGH_RISK: (0, 20),
            OpportunityLevel.HIGH_RISK: (21, 40),
            OpportunityLevel.MODERATE: (41, 60),
            OpportunityLevel.GOOD: (61, 80),
            OpportunityLevel.VERY_GOOD: (81, 100)
        }
        
        # Industry benchmarks (loaded from config or calculated)
        self.industry_benchmarks = {}
        self.percentile_cache = {}
        
        # Explanation models (for SHAP)
        self.explanation_model = None
        self.feature_names = []
        
        # Initialize explanation model if SHAP available
        if SHAP_AVAILABLE:
            self._initialize_explanation_model()
        
        logger.info("Opportunity Score Calculator initialized for proactive financial services")
    
    def calculate_opportunity_score(self, business_data: pd.DataFrame, 
                                  business_id: str = "unknown",
                                  include_predictions: bool = True,
                                  include_explanations: bool = True) -> OpportunityAssessment:
        """
        Calculate comprehensive opportunity score for a business.
        
        Args:
            business_data: Historical business data
            business_id: Business identifier
            include_predictions: Whether to include revenue forecasts
            include_explanations: Whether to include SHAP explanations
            
        Returns:
            Complete opportunity assessment with financial recommendations
        """
        start_time = time.time()
        logger.info(f"Calculating opportunity score for business {business_id}")
        
        try:
            # Step 1: Calculate feature components using feature engine
            feature_scores = self._calculate_feature_components(business_data)
            
            # Step 2: Calculate individual component scores
            components = self._calculate_component_scores(feature_scores, business_data)
            
            # Step 3: Calculate weighted opportunity score
            opportunity_score = self._calculate_weighted_opportunity_score(components)
            
            # Step 4: Determine opportunity level and confidence
            opportunity_level = self._determine_opportunity_level(opportunity_score)
            confidence_score = self._calculate_confidence_score(components, business_data)
            
            # Step 5: Determine recommended financial action
            recommended_action, loan_necessity, investment_potential = self._determine_financial_recommendation(
                opportunity_score, components, business_data
            )
            
            # Step 5: Generate predictions if requested
            revenue_forecast = None
            trend_analysis = None
            if include_predictions and self.model_orchestrator:
                revenue_forecast, trend_analysis = self._generate_predictions(business_data)
            
            # Step 6: Generate explanations and recommendations
            key_factors, stability_factors, recommendations = self._generate_insights(components, business_data, opportunity_level)
            
            # Step 7: SHAP explanations if available and requested
            shap_values = None
            feature_importance = None
            if include_explanations and SHAP_AVAILABLE and self.explanation_model:
                shap_values, feature_importance = self._generate_shap_explanations(feature_scores)
            
            # Create assessment result
            assessment = OpportunityAssessment(
                business_id=business_id,
                opportunity_score=opportunity_score,
                opportunity_level=opportunity_level,
                confidence_score=confidence_score,
                assessment_timestamp=datetime.now().isoformat(),
                recommended_action=recommended_action,
                loan_necessity=loan_necessity,
                investment_potential=investment_potential,
                components=components,
                component_scores={comp.name: comp.score for comp in components},
                revenue_forecast=revenue_forecast,
                trend_analysis=trend_analysis,
                key_opportunity_factors=key_factors,
                stability_factors=stability_factors,
                recommendations=recommendations,
                shap_values=shap_values,
                feature_importance=feature_importance
            )
            
            processing_time = time.time() - start_time
            logger.info(f"Opportunity assessment completed for {business_id}: {opportunity_score:.1f} ({opportunity_level.korean}) â†’ {recommended_action} in {processing_time:.2f}s")
            
            return assessment
            
        except Exception as e:
            logger.error(f"Opportunity calculation failed for {business_id}: {e}")
            # Return moderate default assessment
            return self._create_default_assessment(business_id, str(e))
    
    def _calculate_feature_components(self, business_data: pd.DataFrame) -> Dict[str, float]:
        """Calculate raw feature components using feature engine."""
        try:
            # Use feature engine to calculate all components
            features = self.feature_engine.calculate_all_features(business_data)
            
            # Extract key risk-related features
            feature_scores = {
                'revenue_change_rate': features.get('revenue_change_score', 50.0),
                'volatility_score': features.get('volatility_score', 50.0),
                'trend_strength': features.get('trend_score', 50.0),
                'seasonality_deviation': features.get('seasonality_deviation_score', 50.0),
                'industry_percentile': features.get('industry_comparison_score', 50.0)
            }
            
            return feature_scores
            
        except Exception as e:
            logger.warning(f"Feature calculation failed, using defaults: {e}")
            return {
                'revenue_change_rate': 50.0,
                'volatility_score': 50.0, 
                'trend_strength': 50.0,
                'seasonality_deviation': 50.0,
                'industry_percentile': 50.0
            }
    
    def _calculate_component_scores(self, feature_scores: Dict[str, float], 
                                  business_data: pd.DataFrame) -> List[RiskComponent]:
        """Calculate normalized component scores with explanations."""
        components = []
        
        # Component 1: Revenue Change Rate (30%)
        revenue_change_raw = feature_scores.get('revenue_change_rate', 50.0)
        revenue_change_score = self._normalize_score(revenue_change_raw, invert=True)  # Higher change = higher risk
        revenue_explanation = self._explain_revenue_change(revenue_change_raw, business_data)
        
        components.append(RiskComponent(
            name='revenue_change',
            korean_name='ë§¤ì¶œë³€í™”ìœ¨', 
            score=revenue_change_score,
            weight=self.component_weights['revenue_change'],
            contribution=revenue_change_score * self.component_weights['revenue_change'],
            percentile=revenue_change_raw,
            status=self._get_component_status(revenue_change_score),
            explanation=revenue_explanation
        ))
        
        # Component 2: Volatility (20%)
        volatility_raw = feature_scores.get('volatility_score', 50.0)
        volatility_score = self._normalize_score(volatility_raw)  # Higher volatility = higher risk
        volatility_explanation = self._explain_volatility(volatility_raw, business_data)
        
        components.append(RiskComponent(
            name='volatility',
            korean_name='ë³€ë™ì„±',
            score=volatility_score,
            weight=self.component_weights['volatility'],
            contribution=volatility_score * self.component_weights['volatility'],
            percentile=volatility_raw,
            status=self._get_component_status(volatility_score),
            explanation=volatility_explanation
        ))
        
        # Component 3: Trend Strength (20%)
        trend_raw = feature_scores.get('trend_strength', 50.0)
        trend_score = self._normalize_score(trend_raw, invert=True)  # Weaker trend = higher risk
        trend_explanation = self._explain_trend(trend_raw, business_data)
        
        components.append(RiskComponent(
            name='trend',
            korean_name='íŠ¸ë Œë“œ',
            score=trend_score,
            weight=self.component_weights['trend'],
            contribution=trend_score * self.component_weights['trend'],
            percentile=trend_raw,
            status=self._get_component_status(trend_score),
            explanation=trend_explanation
        ))
        
        # Component 4: Seasonality Deviation (15%)
        seasonality_raw = feature_scores.get('seasonality_deviation', 50.0)
        seasonality_score = self._normalize_score(seasonality_raw)  # Higher deviation = higher risk
        seasonality_explanation = self._explain_seasonality(seasonality_raw, business_data)
        
        components.append(RiskComponent(
            name='seasonality_deviation',
            korean_name='ê³„ì ˆì„±ì´íƒˆ',
            score=seasonality_score,
            weight=self.component_weights['seasonality_deviation'],
            contribution=seasonality_score * self.component_weights['seasonality_deviation'],
            percentile=seasonality_raw,
            status=self._get_component_status(seasonality_score),
            explanation=seasonality_explanation
        ))
        
        # Component 5: Industry Comparison (15%)
        industry_raw = feature_scores.get('industry_percentile', 50.0)
        industry_score = self._normalize_score(industry_raw, invert=True)  # Lower percentile = higher risk
        industry_explanation = self._explain_industry_comparison(industry_raw, business_data)
        
        components.append(RiskComponent(
            name='industry_comparison',
            korean_name='ì—…ì¢…ë¹„êµ',
            score=industry_score,
            weight=self.component_weights['industry_comparison'],
            contribution=industry_score * self.component_weights['industry_comparison'],
            percentile=industry_raw,
            status=self._get_component_status(industry_score),
            explanation=industry_explanation
        ))
        
        return components
    
    def _calculate_weighted_opportunity_score(self, components: List[RiskComponent]) -> float:
        """
        Calculate final weighted opportunity score.
        Converts risk-based components to opportunity-based scoring.
        """
        # Calculate traditional risk score
        traditional_risk_score = sum(comp.contribution for comp in components)
        
        # Convert risk score to opportunity score
        # High risk components become low opportunity, but with different interpretation
        opportunity_score = self._convert_risk_to_opportunity_score(traditional_risk_score, components)
        
        # Ensure score is within 0-100 range
        opportunity_score = max(0.0, min(100.0, opportunity_score))
        
        return opportunity_score
    
    def _convert_risk_to_opportunity_score(self, risk_score: float, components: List[RiskComponent]) -> float:
        """
        Convert traditional risk score to opportunity score with contextual interpretation.
        
        Args:
            risk_score: Traditional risk score (0-100, higher = more risky)
            components: Component breakdown for context
            
        Returns:
            Opportunity score (0-100, higher = better opportunity)
        """
        # Base conversion: invert the risk score for opportunity perspective
        base_opportunity = 100 - risk_score
        
        # Apply contextual adjustments based on component analysis
        adjustments = []
        
        # Revenue change analysis - high growth = opportunity boost
        revenue_comp = next((c for c in components if c.name == 'revenue_change'), None)
        if revenue_comp:
            if revenue_comp.percentile > 70:  # Strong revenue growth
                adjustments.append(10)
            elif revenue_comp.percentile < 30:  # Revenue decline
                adjustments.append(-15)
        
        # Trend analysis - positive trends boost opportunity
        trend_comp = next((c for c in components if c.name == 'trend'), None)
        if trend_comp:
            if trend_comp.percentile > 75:  # Strong upward trend
                adjustments.append(15)
            elif trend_comp.percentile < 25:  # Declining trend
                adjustments.append(-10)
        
        # Industry comparison - better than average = opportunity
        industry_comp = next((c for c in components if c.name == 'industry_comparison'), None)
        if industry_comp:
            if industry_comp.percentile > 80:  # Industry leader
                adjustments.append(12)
            elif industry_comp.percentile < 20:  # Industry laggard
                adjustments.append(-8)
        
        # Apply adjustments with damping to prevent extreme swings
        total_adjustment = sum(adjustments)
        damped_adjustment = total_adjustment * 0.3  # Damp the adjustment by 70%
        
        final_score = base_opportunity + damped_adjustment
        
        return final_score
    
    def _determine_opportunity_level(self, opportunity_score: float) -> OpportunityLevel:
        """Determine opportunity level based on score thresholds."""
        for opportunity_level, (min_score, max_score) in self.opportunity_thresholds.items():
            if min_score <= opportunity_score <= max_score:
                return opportunity_level
        
        # Default to moderate if score is outside thresholds
        return OpportunityLevel.MODERATE
    
    def _determine_financial_recommendation(self, opportunity_score: float, 
                                           components: List[RiskComponent],
                                           business_data: pd.DataFrame) -> Tuple[str, float, float]:
        """
        Determine financial service recommendation based on opportunity score.
        
        Args:
            opportunity_score: Calculated opportunity score (0-100)
            components: Component breakdown for context
            business_data: Historical business data for loan calculation
            
        Returns:
            Tuple of (recommended_action, loan_necessity, investment_potential)
        """
        # Calculate monthly revenue for loan calculations
        try:
            monthly_revenue = self._estimate_monthly_revenue(business_data)
        except:
            monthly_revenue = 10000000  # Default 10M KRW
        
        if opportunity_score <= 20:
            # ë§¤ìš°ìœ„í—˜: ê¸´ê¸‰ ëŒ€ì¶œ í•„ìš”
            recommended_action = "emergency_loan"
            # ìœ„í—˜êµ°(40ì )ê¹Œì§€ ì˜¬ë¦¬ê¸° ìœ„í•œ í•„ìš” ëŒ€ì¶œ ê³„ì‚°
            target_score = 40
            score_gap = target_score - opportunity_score
            loan_necessity = monthly_revenue * (score_gap / 100.0) * 3.0  # 3ë°°ìˆ˜ ì ìš©
            investment_potential = 0.0
            
        elif opportunity_score <= 40:
            # ìœ„í—˜êµ°: ì•ˆì •í™” ëŒ€ì¶œ ì¶”ì²œ
            recommended_action = "stabilization_loan"
            # ì ì •(60ì )ê¹Œì§€ ì˜¬ë¦¬ê¸° ìœ„í•œ í•„ìš” ëŒ€ì¶œ ê³„ì‚°
            target_score = 60
            score_gap = target_score - opportunity_score
            loan_necessity = monthly_revenue * (score_gap / 100.0) * 2.0  # 2ë°°ìˆ˜ ì ìš©
            investment_potential = 10.0
            
        elif opportunity_score <= 60:
            # ì ì •: ëª¨ë‹ˆí„°ë§ ì§€ì†
            recommended_action = "monitoring"
            loan_necessity = 0.0
            investment_potential = 30.0
            
        elif opportunity_score <= 80:
            # ì¢‹ìŒ: íˆ¬ì ê¸°íšŒ ì œê³µ
            recommended_action = "growth_investment"
            loan_necessity = 0.0
            investment_potential = 75.0
            
        else:
            # ë§¤ìš°ì¢‹ìŒ: ê³ ìˆ˜ìµ íˆ¬ì ì¶”ì²œ
            recommended_action = "high_yield_investment"
            loan_necessity = 0.0
            investment_potential = 95.0
        
        # ì»´í¬ë„ŒíŠ¸ ë¶„ì„ ê¸°ë°˜ ì„¸ë¶€ ì¡°ì •
        loan_necessity, investment_potential = self._adjust_recommendations_by_components(
            loan_necessity, investment_potential, components
        )
        
        return recommended_action, loan_necessity, investment_potential
    
    def _estimate_monthly_revenue(self, business_data: pd.DataFrame) -> float:
        """Estimate monthly revenue from business data."""
        revenue_columns = ['monthly_revenue', 'revenue', 'sales', 'y']
        
        for col in revenue_columns:
            if col in business_data.columns and not business_data[col].isna().all():
                recent_revenue = business_data[col].dropna().tail(6).mean()  # Last 6 months average
                return max(1000000, recent_revenue)  # Minimum 1M KRW
        
        # If no revenue data found, return reasonable default
        return 10000000  # 10M KRW default
    
    def _adjust_recommendations_by_components(self, loan_necessity: float, investment_potential: float,
                                            components: List[RiskComponent]) -> Tuple[float, float]:
        """Adjust financial recommendations based on component analysis."""
        
        # Revenue trend adjustment
        trend_comp = next((c for c in components if c.name == 'trend'), None)
        if trend_comp:
            if trend_comp.percentile > 80:  # Strong growth trend
                loan_necessity *= 0.8  # Less loan needed
                investment_potential += 15  # More investment potential
            elif trend_comp.percentile < 20:  # Declining trend
                loan_necessity *= 1.3  # More loan needed
                investment_potential = max(0, investment_potential - 20)  # Less investment potential
        
        # Volatility adjustment
        volatility_comp = next((c for c in components if c.name == 'volatility'), None)
        if volatility_comp:
            if volatility_comp.score > 80:  # High volatility
                loan_necessity *= 1.2  # More stabilization needed
                investment_potential *= 0.7  # Riskier for investment
        
        # Industry position adjustment
        industry_comp = next((c for c in components if c.name == 'industry_comparison'), None)
        if industry_comp:
            if industry_comp.percentile > 85:  # Industry leader
                investment_potential += 10  # Premium investment opportunity
            elif industry_comp.percentile < 15:  # Industry laggard
                loan_necessity *= 1.15  # May need more support
        
        # Ensure reasonable bounds
        loan_necessity = max(0, loan_necessity)
        investment_potential = max(0, min(100, investment_potential))
        
        return loan_necessity, investment_potential
    
    def _calculate_confidence_score(self, components: List[RiskComponent], 
                                  business_data: pd.DataFrame) -> float:
        """Calculate confidence in the risk assessment."""
        confidence_factors = []
        
        # Factor 1: Data quality (amount of historical data)
        data_quality_score = min(1.0, len(business_data) / 12.0)  # 12 quarters = full confidence
        confidence_factors.append(data_quality_score)
        
        # Factor 2: Component consistency (low variance between components = higher confidence)
        component_scores = [comp.score for comp in components]
        if len(component_scores) > 1:
            consistency_score = 1.0 - (np.std(component_scores) / 100.0)  # Normalize by max std
            confidence_factors.append(max(0.0, consistency_score))
        
        # Factor 3: Extreme value detection (scores near middle = higher confidence)
        extreme_penalty = 0.0
        for comp in components:
            if comp.score < 10 or comp.score > 90:  # Very extreme scores
                extreme_penalty += 0.1
        
        extreme_confidence = max(0.0, 1.0 - extreme_penalty)
        confidence_factors.append(extreme_confidence)
        
        # Calculate weighted confidence score
        confidence_score = np.mean(confidence_factors)
        return min(1.0, max(0.0, confidence_score))
    
    def _generate_predictions(self, business_data: pd.DataFrame) -> Tuple[Optional[pd.DataFrame], Optional[Dict]]:
        """Generate revenue forecasts and trend analysis."""
        if not self.model_orchestrator:
            return None, None
        
        try:
            # Create future data for next 4 quarters
            last_date = business_data['ds'].max() if 'ds' in business_data.columns else datetime.now()
            future_dates = pd.date_range(start=last_date, periods=5, freq='Q')[1:]  # Skip first (current)
            
            future_data = pd.DataFrame({
                'ds': future_dates,
                'y': np.nan  # Will be predicted
            })
            
            # Request prediction
            request = PredictionRequest(future_data=future_data)
            result = self.model_orchestrator.predict(request)
            
            if not result.predictions.empty:
                # Trend analysis
                trend_analysis = {
                    'forecast_direction': 'increasing' if result.predictions['ensemble_pred'].diff().mean() > 0 else 'decreasing',
                    'forecast_volatility': result.predictions['ensemble_pred'].std(),
                    'confidence': result.confidence_score,
                    'model_used': result.model_used
                }
                
                return result.predictions, trend_analysis
            else:
                return None, None
                
        except Exception as e:
            logger.warning(f"Prediction generation failed: {e}")
            return None, None
    
    def _generate_insights(self, components: List[RiskComponent], 
                         business_data: pd.DataFrame,
                         opportunity_level: OpportunityLevel) -> Tuple[List[str], List[str], List[str]]:
        """Generate key opportunity factors, stability factors, and recommendations."""
        key_opportunity_factors = []
        stability_factors = []
        recommendations = []
        
        # Identify key opportunity factors based on opportunity level
        if opportunity_level in [OpportunityLevel.GOOD, OpportunityLevel.VERY_GOOD]:
            # Focus on growth and investment factors
            growth_components = [comp for comp in components 
                               if comp.name in ['trend', 'revenue_change', 'industry_comparison'] 
                               and comp.percentile > 60]
            for comp in growth_components:
                key_opportunity_factors.append(f"âœ… {comp.korean_name}: {comp.explanation} (ì„±ì¥ ê¸°íšŒ)")
        else:
            # Focus on risk mitigation factors
            high_concern_components = [comp for comp in components if comp.score > 70]
            for comp in high_concern_components:
                key_opportunity_factors.append(f"âš ï¸ {comp.korean_name}: {comp.explanation} (ê°œì„  í•„ìš”)")
        
        # Identify stability factors (consistent, reliable components)
        stable_components = [comp for comp in components 
                           if comp.name in ['volatility', 'seasonality_deviation'] 
                           and comp.score < 50]
        for comp in stable_components:
            stability_factors.append(f"ğŸŸ¢ {comp.korean_name}: {comp.explanation} (ì•ˆì • ìš”ì†Œ)")
        
        # Generate recommendations based on opportunity level and components
        recommendations = self._generate_opportunity_recommendations(components, business_data, opportunity_level)
        
        return key_opportunity_factors, stability_factors, recommendations
    
    def _generate_opportunity_recommendations(self, components: List[RiskComponent], 
                                            business_data: pd.DataFrame,
                                            opportunity_level: OpportunityLevel) -> List[str]:
        """Generate specific business recommendations based on opportunity level."""
        recommendations = []
        
        # Level-specific recommendations
        if opportunity_level == OpportunityLevel.VERY_HIGH_RISK:
            recommendations.extend([
                "ğŸ’° ê¸´ê¸‰ ìš´ì˜ìê¸ˆ ëŒ€ì¶œì„ í†µí•œ í˜„ê¸ˆíë¦„ ì•ˆì •í™”",
                "ğŸ“Š ì£¼ìš” ìœ„í—˜ìš”ì¸ì— ëŒ€í•œ ì¦‰ì‹œ ê°œì„  ì¡°ì¹˜ í•„ìš”",
                "ğŸ” ì „ë¬¸ ê²½ì˜ ì»¨ì„¤íŒ…ì„ í†µí•œ ì‚¬ì—… êµ¬ì¡° ì ê²€",
                "âš¡ ë‹¨ê¸° ë¹„ìš© ì ˆê°ì„ í†µí•œ ì†ìµë¶„ê¸°ì  ë‹¬ì„±"
            ])
        elif opportunity_level == OpportunityLevel.HIGH_RISK:
            recommendations.extend([
                "ğŸ’³ ì•ˆì •í™” ëŒ€ì¶œì„ í†µí•œ ì ì • ìˆ˜ì¤€ìœ¼ë¡œì˜ ê°œì„ ",
                "ğŸ“ˆ ë§¤ì¶œ ë‹¤ê°í™” ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰",
                "ğŸ›¡ï¸ ë³€ë™ì„± ì™„í™”ë¥¼ ìœ„í•œ ê³ ì •ë¹„ìš© ê´€ë¦¬",
                "ğŸ¯ ì—…ì¢… í‰ê·  ìˆ˜ì¤€ ë‹¬ì„±ì„ ìœ„í•œ ë²¤ì¹˜ë§ˆí‚¹"
            ])
        elif opportunity_level == OpportunityLevel.MODERATE:
            recommendations.extend([
                "ğŸ“Š ì •ê¸°ì ì¸ ì¬ë¬´ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•",
                "ğŸ“ˆ ì„±ì¥ ë™ë ¥ ë°œêµ´ì„ ìœ„í•œ ì‹œì¥ ê¸°íšŒ íƒìƒ‰",
                "ğŸ’¡ ìš´ì˜ íš¨ìœ¨ì„± ê°œì„ ì„ í†µí•œ ìˆ˜ìµì„± í–¥ìƒ",
                "ğŸ”„ ê³„ì ˆì„± ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½"
            ])
        elif opportunity_level == OpportunityLevel.GOOD:
            recommendations.extend([
                "ğŸš€ ì„±ì¥íˆ¬ì ê¸°íšŒ í™œìš©ì„ í†µí•œ ì‚¬ì—… í™•ì¥",
                "ğŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤ ë‹¤ë³€í™” íˆ¬ì ê²€í† ",
                "ğŸ† ì‹œì¥ ë¦¬ë”ì‹­ ê°•í™”ë¥¼ ìœ„í•œ í˜ì‹  íˆ¬ì",
                "ğŸ“Š ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œ ë„ì…"
            ])
        else:  # VERY_GOOD
            recommendations.extend([
                "ğŸ’ ê³ ìˆ˜ìµ íˆ¬ììƒí’ˆì„ í†µí•œ ìì‚° ì¦ì‹",
                "ğŸŒŸ í”„ë¦¬ë¯¸ì—„ íˆ¬ì ê¸°íšŒ ìš°ì„  ì ‘ê·¼ê¶Œ í™œìš©",
                "ğŸ”¥ ì‹ ì‚¬ì—… ì˜ì—­ ì§„ì¶œì„ ìœ„í•œ ì „ëµì  íˆ¬ì",
                "ğŸ… ì—…ê³„ ì„ ë„ ê¸°ì—…ìœ¼ë¡œì„œì˜ ESG íˆ¬ì ê²€í† "
            ])
        
        # Component-specific recommendations
        for comp in sorted(components, key=lambda x: x.contribution, reverse=True)[:2]:
            if comp.score > 70:  # High concern components
                if comp.name == 'revenue_change':
                    recommendations.append("ğŸ’° ë§¤ì¶œ ì•ˆì •ì„± ê°œì„ ì„ ìœ„í•œ ê³ ê° ë‹¤ë³€í™” ì „ëµ")
                elif comp.name == 'volatility':
                    recommendations.append("ğŸ“‰ ë§¤ì¶œ ë³€ë™ì„± ì™„í™”ë¥¼ ìœ„í•œ êµ¬ì¡°ì  ê°œì„ ")
                elif comp.name == 'trend':
                    recommendations.append("ğŸ“ˆ ì„±ì¥ íŠ¸ë Œë“œ íšŒë³µì„ ìœ„í•œ ë§ˆì¼€íŒ… ê°•í™”")
            elif comp.score < 30:  # Strong performance components
                if comp.name == 'industry_comparison':
                    recommendations.append("ğŸ† ì—…ê³„ ìš°ìœ„ë¥¼ í™œìš©í•œ ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€")
                elif comp.name == 'trend':
                    recommendations.append("ğŸš€ ê°•ë ¥í•œ ì„±ì¥ì„¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì ê·¹ì  í™•ì¥")
        
        return recommendations[:5]  # Limit to top 5 recommendations
    
    def _generate_recommendations(self, components: List[RiskComponent], 
                                business_data: pd.DataFrame) -> List[str]:
        """Generate specific business recommendations."""
        recommendations = []
        
        # Sort components by contribution (highest risk first)
        sorted_components = sorted(components, key=lambda x: x.contribution, reverse=True)
        
        for comp in sorted_components[:3]:  # Top 3 risk factors
            if comp.name == 'revenue_change':
                if comp.score > 70:
                    recommendations.append("ë§¤ì¶œ ì•ˆì •ì„± ê°œì„ ì„ ìœ„í•œ ë‹¤ê°í™” ì „ëµ ê²€í† ")
                    recommendations.append("ê³„ì ˆì  ë³€ë™ì— ëŒ€ë¹„í•œ í˜„ê¸ˆ íë¦„ ê´€ë¦¬")
                    
            elif comp.name == 'volatility':
                if comp.score > 70:
                    recommendations.append("ë§¤ì¶œ ë³€ë™ì„± ê°ì†Œë¥¼ ìœ„í•œ ê³ ì • ê³ ê° í™•ë³´")
                    recommendations.append("ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìˆ˜ìµì› ê°œë°œ")
                    
            elif comp.name == 'trend':
                if comp.score > 70:
                    recommendations.append("ì„±ì¥ ë™ë ¥ íšŒë³µì„ ìœ„í•œ ë§ˆì¼€íŒ… ì „ëµ ê°•í™”")
                    recommendations.append("ì‹ ê·œ ì‹œì¥ ê°œì²™ ë˜ëŠ” ìƒí’ˆ ê°œë°œ")
                    
            elif comp.name == 'seasonality_deviation':
                if comp.score > 70:
                    recommendations.append("ê³„ì ˆì„± íŒ¨í„´ ë¶„ì„ ë° ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½")
                    recommendations.append("ë¹„ìˆ˜ê¸° ëŒ€ë¹„ ë¹„ìš© êµ¬ì¡° ìµœì í™”")
                    
            elif comp.name == 'industry_comparison':
                if comp.score > 70:
                    recommendations.append("ì—…ì¢… í‰ê·  ëŒ€ë¹„ ê²½ìŸë ¥ ê°•í™” ë°©ì•ˆ ëª¨ìƒ‰")
                    recommendations.append("ì—…ê³„ ëª¨ë²” ì‚¬ë¡€ ë²¤ì¹˜ë§ˆí‚¹")
        
        # Add general recommendations
        if len([comp for comp in components if comp.score > 70]) >= 3:
            recommendations.append("ì¢…í•©ì ì¸ ì‚¬ì—… êµ¬ì¡° ê°œì„  ê³„íš ìˆ˜ë¦½ ê¶Œì¥")
            recommendations.append("ì „ë¬¸ ê²½ì˜ ì»¨ì„¤íŒ… ì„œë¹„ìŠ¤ ì´ìš© ê²€í† ")
        
        return recommendations[:5]  # Limit to top 5 recommendations
    
    def _normalize_score(self, raw_score: float, invert: bool = False) -> float:
        """
        Normalize score to 0-100 risk scale.
        
        Args:
            raw_score: Raw score (usually percentile 0-100)
            invert: Whether to invert score (higher raw = lower risk)
            
        Returns:
            Normalized risk score (0=low risk, 100=high risk)
        """
        if invert:
            # Higher raw score = lower risk (e.g., better industry percentile)
            normalized = 100.0 - raw_score
        else:
            # Higher raw score = higher risk (e.g., higher volatility)
            normalized = raw_score
        
        return max(0.0, min(100.0, normalized))
    
    def _get_component_status(self, score: float) -> str:
        """Get status description for component score."""
        if score <= 30:
            return "ì–‘í˜¸"
        elif score <= 50:
            return "ë³´í†µ"
        elif score <= 70:
            return "ì£¼ì˜"
        else:
            return "ìœ„í—˜"
    
    def _explain_revenue_change(self, raw_score: float, business_data: pd.DataFrame) -> str:
        """Generate explanation for revenue change component."""
        if raw_score > 80:
            return "ë§¤ì¶œ ë³€í™”ìœ¨ì´ ë§¤ìš° ë†’ì•„ ë¶ˆì•ˆì •ì„± ìš°ë ¤"
        elif raw_score > 60:
            return "ë§¤ì¶œ ë³€í™”ìœ¨ì´ ë†’ì•„ ì£¼ì˜ í•„ìš”"
        elif raw_score > 40:
            return "ë§¤ì¶œ ë³€í™”ìœ¨ì´ ë³´í†µ ìˆ˜ì¤€"
        else:
            return "ë§¤ì¶œ ë³€í™”ìœ¨ì´ ì•ˆì •ì "
    
    def _explain_volatility(self, raw_score: float, business_data: pd.DataFrame) -> str:
        """Generate explanation for volatility component.""" 
        if raw_score > 80:
            return "ë§¤ì¶œ ë³€ë™ì„±ì´ ë§¤ìš° ë†’ìŒ"
        elif raw_score > 60:
            return "ë§¤ì¶œ ë³€ë™ì„±ì´ ë†’ìŒ"
        elif raw_score > 40:
            return "ë§¤ì¶œ ë³€ë™ì„±ì´ ë³´í†µ ìˆ˜ì¤€"
        else:
            return "ë§¤ì¶œ ë³€ë™ì„±ì´ ë‚®ì•„ ì•ˆì •ì "
    
    def _explain_trend(self, raw_score: float, business_data: pd.DataFrame) -> str:
        """Generate explanation for trend component."""
        if raw_score > 80:
            return "ë§¤ì¶œ ìƒìŠ¹ íŠ¸ë Œë“œê°€ ê°•í•¨"
        elif raw_score > 60:
            return "ë§¤ì¶œ ìƒìŠ¹ íŠ¸ë Œë“œê°€ ì–‘í˜¸"
        elif raw_score > 40:
            return "ë§¤ì¶œ íŠ¸ë Œë“œê°€ ë³´í†µ"
        else:
            return "ë§¤ì¶œ í•˜í–¥ íŠ¸ë Œë“œ ë˜ëŠ” íŠ¸ë Œë“œ ì•½í•¨"
    
    def _explain_seasonality(self, raw_score: float, business_data: pd.DataFrame) -> str:
        """Generate explanation for seasonality deviation component."""
        if raw_score > 80:
            return "ê³„ì ˆì„± íŒ¨í„´ì—ì„œ í¬ê²Œ ë²—ì–´ë‚¨"
        elif raw_score > 60:
            return "ê³„ì ˆì„± íŒ¨í„´ì—ì„œ ë‹¤ì†Œ ë²—ì–´ë‚¨"
        elif raw_score > 40:
            return "ê³„ì ˆì„± íŒ¨í„´ì´ ë³´í†µ ìˆ˜ì¤€"
        else:
            return "ê³„ì ˆì„± íŒ¨í„´ì´ ì˜ˆì¸¡ ê°€ëŠ¥í•¨"
    
    def _explain_industry_comparison(self, raw_score: float, business_data: pd.DataFrame) -> str:
        """Generate explanation for industry comparison component."""
        if raw_score > 80:
            return f"ì—…ì¢… ë‚´ ìƒìœ„ {100-raw_score:.0f}% ìˆ˜ì¤€"
        elif raw_score > 60:
            return f"ì—…ì¢… í‰ê·  ì´ìƒ (ìƒìœ„ {100-raw_score:.0f}%)"
        elif raw_score > 40:
            return "ì—…ì¢… í‰ê·  ìˆ˜ì¤€"
        else:
            return f"ì—…ì¢… í‰ê·  ì´í•˜ (í•˜ìœ„ {raw_score:.0f}%)"
    
    def _initialize_explanation_model(self) -> None:
        """Initialize SHAP explanation model."""
        if not SHAP_AVAILABLE:
            return
        
        try:
            # Simple explanation model using synthetic data
            self.feature_names = ['revenue_change', 'volatility', 'trend', 'seasonality', 'industry_position']
            
            # Create synthetic training data for explanation model
            n_samples = 1000
            X_train = np.random.rand(n_samples, len(self.feature_names)) * 100
            
            # Synthetic risk scores based on weighted combination
            y_train = (X_train[:, 0] * 0.3 +  # revenue_change
                      X_train[:, 1] * 0.2 +  # volatility
                      (100 - X_train[:, 2]) * 0.2 +  # trend (inverted)
                      X_train[:, 3] * 0.15 +  # seasonality
                      (100 - X_train[:, 4]) * 0.15)  # industry (inverted)
            
            # Train simple explanation model
            self.explanation_model = RandomForestRegressor(n_estimators=50, random_state=42)
            self.explanation_model.fit(X_train, y_train)
            
            logger.info("SHAP explanation model initialized")
            
        except Exception as e:
            logger.warning(f"Failed to initialize explanation model: {e}")
            self.explanation_model = None
    
    def _generate_shap_explanations(self, feature_scores: Dict[str, float]) -> Tuple[Optional[Dict], Optional[Dict]]:
        """Generate SHAP explanations for risk assessment."""
        if not SHAP_AVAILABLE or not self.explanation_model:
            return None, None
        
        try:
            # Prepare feature vector
            feature_vector = np.array([[
                feature_scores.get('revenue_change_rate', 50.0),
                feature_scores.get('volatility_score', 50.0), 
                feature_scores.get('trend_strength', 50.0),
                feature_scores.get('seasonality_deviation', 50.0),
                feature_scores.get('industry_percentile', 50.0)
            ]])
            
            # Calculate SHAP values
            explainer = shap.TreeExplainer(self.explanation_model)
            shap_values = explainer.shap_values(feature_vector)
            
            # Convert to dictionary
            shap_dict = {name: float(value) for name, value in zip(self.feature_names, shap_values[0])}
            
            # Feature importance (absolute SHAP values)
            importance_dict = {name: abs(value) for name, value in shap_dict.items()}
            
            return shap_dict, importance_dict
            
        except Exception as e:
            logger.warning(f"SHAP explanation generation failed: {e}")
            return None, None
    
    def _create_default_assessment(self, business_id: str, error_message: str) -> OpportunityAssessment:
        """Create default moderate assessment when calculation fails."""
        default_components = []
        
        for name, korean_name in [
            ('revenue_change', 'ë§¤ì¶œë³€í™”ìœ¨'),
            ('volatility', 'ë³€ë™ì„±'),
            ('trend', 'íŠ¸ë Œë“œ'),
            ('seasonality_deviation', 'ê³„ì ˆì„±ì´íƒˆ'),
            ('industry_comparison', 'ì—…ì¢…ë¹„êµ')
        ]:
            component = RiskComponent(
                name=name,
                korean_name=korean_name,
                score=50.0,
                weight=self.component_weights.get(name, 0.2),
                contribution=50.0 * self.component_weights.get(name, 0.2),
                percentile=50.0,
                status="ë¶ˆëª…",
                explanation="ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ í‰ê°€ ë¶ˆê°€"
            )
            default_components.append(component)
        
        return OpportunityAssessment(
            business_id=business_id,
            opportunity_score=50.0,
            opportunity_level=OpportunityLevel.MODERATE,
            confidence_score=0.0,
            assessment_timestamp=datetime.now().isoformat(),
            recommended_action="monitoring",
            loan_necessity=0.0,
            investment_potential=0.0,
            components=default_components,
            component_scores={comp.name: comp.score for comp in default_components},
            key_opportunity_factors=[f"í‰ê°€ ì˜¤ë¥˜: {error_message}"],
            stability_factors=[],
            recommendations=["ë°ì´í„° í’ˆì§ˆ ê°œì„  í›„ ì¬í‰ê°€ ê¶Œì¥"]
        )
    
    def batch_calculate_opportunity_scores(self, business_data_list: List[Tuple[str, pd.DataFrame]],
                                         include_predictions: bool = False,
                                         include_explanations: bool = False) -> List[OpportunityAssessment]:
        """
        Calculate opportunity scores for multiple businesses efficiently.
        
        Args:
            business_data_list: List of (business_id, data) tuples
            include_predictions: Whether to include forecasts
            include_explanations: Whether to include SHAP explanations
            
        Returns:
            List of opportunity assessments
        """
        logger.info(f"Calculating opportunity scores for {len(business_data_list)} businesses")
        
        results = []
        for business_id, business_data in business_data_list:
            try:
                assessment = self.calculate_opportunity_score(
                    business_data=business_data,
                    business_id=business_id,
                    include_predictions=include_predictions,
                    include_explanations=include_explanations
                )
                results.append(assessment)
            except Exception as e:
                logger.error(f"Failed to calculate opportunity for {business_id}: {e}")
                results.append(self._create_default_assessment(business_id, str(e)))
        
        return results
    
    def export_opportunity_assessment_json(self, assessment: OpportunityAssessment) -> str:
        """Export opportunity assessment to JSON format."""
        assessment_dict = {
            'business_id': assessment.business_id,
            'opportunity_score': assessment.opportunity_score,
            'opportunity_level': {
                'level': assessment.opportunity_level.level,
                'korean': assessment.opportunity_level.korean,
                'english': assessment.opportunity_level.english,
                'color': assessment.opportunity_level.color
            },
            'confidence_score': assessment.confidence_score,
            'assessment_timestamp': assessment.assessment_timestamp,
            'financial_recommendations': {
                'recommended_action': assessment.recommended_action,
                'loan_necessity': assessment.loan_necessity,
                'investment_potential': assessment.investment_potential
            },
            'components': [
                {
                    'name': comp.name,
                    'korean_name': comp.korean_name,
                    'score': comp.score,
                    'weight': comp.weight,
                    'contribution': comp.contribution,
                    'percentile': comp.percentile,
                    'status': comp.status,
                    'explanation': comp.explanation
                }
                for comp in assessment.components
            ],
            'key_opportunity_factors': assessment.key_opportunity_factors,
            'stability_factors': assessment.stability_factors,
            'recommendations': assessment.recommendations
        }
        
        if assessment.shap_values:
            assessment_dict['shap_values'] = assessment.shap_values
            assessment_dict['feature_importance'] = assessment.feature_importance
        
        if assessment.revenue_forecast is not None:
            assessment_dict['revenue_forecast'] = assessment.revenue_forecast.to_dict('records')
            
        if assessment.trend_analysis:
            assessment_dict['trend_analysis'] = assessment.trend_analysis
        
        return json.dumps(assessment_dict, ensure_ascii=False, indent=2)


def main():
    """Main function for testing opportunity score calculator."""
    print("\n=== OPPORTUNITY SCORE CALCULATOR TEST ===")
    
    # Initialize calculator
    calculator = SeoulOpportunityScoreCalculator()
    print(f"Opportunity Score Calculator initialized")
    print(f"Component weights: {calculator.component_weights}")
    print(f"Opportunity thresholds: {[(level.korean, thresholds) for level, thresholds in calculator.opportunity_thresholds.items()]}")
    
    # Test with sample data
    sample_data = pd.DataFrame({
        'ds': pd.date_range('2023-01-01', periods=12, freq='Q'),
        'monthly_revenue': [1000000 + np.random.normal(0, 100000) for _ in range(12)],
        'monthly_transactions': [1000 + np.random.normal(0, 50) for _ in range(12)]
    })
    
    print(f"\nSample business data: {len(sample_data)} quarters")
    
    # Calculate opportunity assessment
    assessment = calculator.calculate_opportunity_score(
        business_data=sample_data,
        business_id="test_business_001",
        include_predictions=False,
        include_explanations=True
    )
    
    print(f"\n=== OPPORTUNITY ASSESSMENT RESULT ===")
    print(f"Business ID: {assessment.business_id}")
    print(f"Opportunity Score: {assessment.opportunity_score:.1f}")
    print(f"Opportunity Level: {assessment.opportunity_level.korean} ({assessment.opportunity_level.english})")
    print(f"Confidence: {assessment.confidence_score:.2f}")
    print(f"Recommended Action: {assessment.recommended_action}")
    if assessment.loan_necessity > 0:
        print(f"Loan Necessity: {assessment.loan_necessity:,.0f} KRW")
    if assessment.investment_potential > 0:
        print(f"Investment Potential: {assessment.investment_potential:.1f}/100")
    
    print(f"\nComponent Scores:")
    for comp in assessment.components:
        print(f"  {comp.korean_name}: {comp.score:.1f} (ê¸°ì—¬ë„: {comp.contribution:.1f})")
    
    print(f"\nRecommendations:")
    for i, rec in enumerate(assessment.recommendations[:3], 1):
        print(f"  {i}. {rec}")
    
    print("\n=== OPPORTUNITY SCORE CALCULATOR READY ===")


if __name__ == "__main__":
    import time
    main()