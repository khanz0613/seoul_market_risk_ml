#!/usr/bin/env python3
"""
ì„œìš¸ ì‹œì¥ ìœ„í—˜ë„ ML ì‹œìŠ¤í…œ - ëª¨ë¸ í›ˆë ¨
Seoul Market Risk ML System - Model Training

79ê°œ ëª¨ë¸(1 Global + 6 Regional + 72 Local)ì„ ì‹¤ì œ ë°ì´í„°ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.
"""

import sys
import os
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta
from pathlib import Path
import time
import logging
import warnings
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

# Basic ML imports (avoiding LightGBM)
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import joblib

# System imports
from src.utils.config_loader import load_config, get_data_paths

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SeoulModelTrainer:
    """ì„œìš¸ ì‹œì¥ ìœ„í—˜ë„ ML ëª¨ë¸ í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.config = load_config()
        self.data_paths = get_data_paths(self.config)
        self.models_dir = Path("models")
        self.models_dir.mkdir(exist_ok=True)
        
        # ëª¨ë¸ ì„±ëŠ¥ ì¶”ì 
        self.model_performance = {}
        self.training_results = {
            'start_time': datetime.now(),
            'models_trained': 0,
            'models_failed': 0,
            'performance_summary': {},
            'errors': []
        }
        
    def load_training_data(self) -> pd.DataFrame:
        """í›ˆë ¨ ë°ì´í„° ë¡œë“œ"""
        logger.info("ğŸ“Š í›ˆë ¨ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        combined_file = self.data_paths['processed'] / 'seoul_sales_combined.csv'
        
        if not combined_file.exists():
            raise FileNotFoundError(f"ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {combined_file}")
        
        df = pd.read_csv(combined_file)
        logger.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,} í–‰, {len(df.columns)} ì»¬ëŸ¼")
        
        return df
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ë° ì¤€ë¹„"""
        logger.info("ğŸ”§ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")
        
        # ê¸°ë³¸ íŠ¹ì„± ì„ íƒ
        feature_columns = [
            'district_code', 'business_type_code', 'quarter', 'year',
            'weekday_revenue', 'weekend_revenue',
            'male_revenue', 'female_revenue'
        ]
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_features = [col for col in feature_columns if col in df.columns]
        
        if not available_features:
            # ìµœì†Œí•œì˜ íŠ¹ì„±ìœ¼ë¡œ ëŒ€ì²´
            available_features = ['district_code', 'business_type_code', 'year', 'quarter']
        
        # íƒ€ê²Ÿ ë³€ìˆ˜
        target_col = 'monthly_revenue'
        if target_col not in df.columns:
            raise ValueError(f"íƒ€ê²Ÿ ë³€ìˆ˜ '{target_col}'ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤")
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        for col in available_features:
            if df[col].dtype in ['object']:
                df[col] = df[col].fillna('unknown')
                # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
                df[col] = pd.Categorical(df[col]).codes
            else:
                df[col] = df[col].fillna(df[col].median())
        
        df[target_col] = df[target_col].fillna(df[target_col].median())
        
        # ì´ìƒì¹˜ ì œê±° (ìƒìœ„/í•˜ìœ„ 1% ì œê±°)
        target_q99 = df[target_col].quantile(0.99)
        target_q01 = df[target_col].quantile(0.01)
        df = df[(df[target_col] >= target_q01) & (df[target_col] <= target_q99)]
        
        X = df[available_features]
        y = df[target_col]
        
        logger.info(f"íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ: {len(available_features)}ê°œ íŠ¹ì„±, {len(df):,} ìƒ˜í”Œ")
        return X, y
    
    def train_global_model(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """ê¸€ë¡œë²Œ ëª¨ë¸ í›ˆë ¨"""
        logger.info("ğŸŒ ê¸€ë¡œë²Œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        try:
            start_time = time.time()
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±
            models = {
                'random_forest': RandomForestRegressor(
                    n_estimators=100, 
                    max_depth=10, 
                    random_state=42,
                    n_jobs=-1
                ),
                'ridge': Ridge(alpha=1.0),
                'linear': LinearRegression()
            }
            
            trained_models = {}
            model_scores = {}
            
            # ê° ëª¨ë¸ í›ˆë ¨
            for model_name, model in models.items():
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                # ì„±ëŠ¥ í‰ê°€
                mse = mean_squared_error(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                
                trained_models[model_name] = model
                model_scores[model_name] = {
                    'mse': mse,
                    'mae': mae,
                    'r2': r2,
                    'rmse': np.sqrt(mse)
                }
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ (R2 ê¸°ì¤€)
            best_model_name = max(model_scores.keys(), key=lambda x: model_scores[x]['r2'])
            best_model = trained_models[best_model_name]
            best_score = model_scores[best_model_name]
            
            # ëª¨ë¸ ì €ì¥
            model_path = self.models_dir / 'global_model.joblib'
            joblib.dump(best_model, model_path)
            
            training_time = time.time() - start_time
            
            result = {
                'model_type': 'global',
                'model_name': best_model_name,
                'model_path': str(model_path),
                'performance': best_score,
                'all_models_performance': model_scores,
                'training_time': training_time,
                'training_samples': len(X_train),
                'test_samples': len(X_test)
            }
            
            self.model_performance['global'] = result
            self.training_results['models_trained'] += 1
            
            logger.info(f"âœ… ê¸€ë¡œë²Œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ({training_time:.1f}ì´ˆ)")
            logger.info(f"   ìµœê³  ëª¨ë¸: {best_model_name}, R2: {best_score['r2']:.3f}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ê¸€ë¡œë²Œ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            self.training_results['models_failed'] += 1
            self.training_results['errors'].append(f"global: {str(e)}")
            return None
    
    def train_regional_models(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """ì§€ì—­ ëª¨ë¸ í›ˆë ¨ (6ê°œ ì§€ì—­)"""
        logger.info("ğŸ™ï¸ ì§€ì—­ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (6ê°œ ì§€ì—­)...")
        
        regional_results = {}
        
        # district_codeê°€ ì§€ì—­ IDë¼ê³  ê°€ì •
        if 'district_code' not in X.columns:
            logger.warning("district_code ì»¬ëŸ¼ì´ ì—†ì–´ ì§€ì—­ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        unique_regions = sorted(X['district_code'].unique())[:6]  # ìµœëŒ€ 6ê°œ ì§€ì—­
        
        for region_id in unique_regions:
            try:
                logger.info(f"   ì§€ì—­ {region_id} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
                start_time = time.time()
                
                # ì§€ì—­ë³„ ë°ì´í„° í•„í„°ë§
                region_mask = X['district_code'] == region_id
                X_region = X[region_mask]
                y_region = y[region_mask]
                
                if len(X_region) < 50:  # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ í™•ì¸
                    logger.warning(f"   ì§€ì—­ {region_id}: ë°ì´í„° ë¶€ì¡± ({len(X_region)}ê°œ), ìŠ¤í‚µ")
                    continue
                
                # ì§€ì—­ë³„ ë°ì´í„° ë¶„í• 
                X_train, X_test, y_train, y_test = train_test_split(
                    X_region, y_region, test_size=0.2, random_state=42
                )
                
                # ì§€ì—­ë³„ ëª¨ë¸ (Random Forest ì‚¬ìš©)
                model = RandomForestRegressor(
                    n_estimators=50, 
                    max_depth=8, 
                    random_state=42,
                    n_jobs=2
                )
                
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                # ì„±ëŠ¥ í‰ê°€
                mse = mean_squared_error(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                
                # ëª¨ë¸ ì €ì¥
                model_path = self.models_dir / f'regional_model_{region_id}.joblib'
                joblib.dump(model, model_path)
                
                training_time = time.time() - start_time
                
                result = {
                    'model_type': 'regional',
                    'region_id': region_id,
                    'model_path': str(model_path),
                    'performance': {
                        'mse': mse,
                        'mae': mae,
                        'r2': r2,
                        'rmse': np.sqrt(mse)
                    },
                    'training_time': training_time,
                    'training_samples': len(X_train),
                    'test_samples': len(X_test)
                }
                
                regional_results[f'region_{region_id}'] = result
                self.training_results['models_trained'] += 1
                
                logger.info(f"   âœ… ì§€ì—­ {region_id} ì™„ë£Œ ({training_time:.1f}ì´ˆ, R2: {r2:.3f})")
                
            except Exception as e:
                logger.error(f"   âŒ ì§€ì—­ {region_id} ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
                self.training_results['models_failed'] += 1
                self.training_results['errors'].append(f"regional_{region_id}: {str(e)}")
        
        self.model_performance.update(regional_results)
        logger.info(f"âœ… ì§€ì—­ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ({len(regional_results)}ê°œ ëª¨ë¸)")
        
        return regional_results
    
    def train_local_models(self, X: pd.DataFrame, y: pd.Series, max_models: int = 20) -> Dict:
        """ë¡œì»¬ ëª¨ë¸ í›ˆë ¨ (ì§€ì—­ x ì—…ì¢… ì¡°í•©, ìµœëŒ€ ê°œìˆ˜ ì œí•œ)"""
        logger.info(f"ğŸª ë¡œì»¬ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (ìµœëŒ€ {max_models}ê°œ)...")
        
        local_results = {}
        
        if 'district_code' not in X.columns or 'business_type_code' not in X.columns:
            logger.warning("district_code ë˜ëŠ” business_type_code ì»¬ëŸ¼ì´ ì—†ì–´ ë¡œì»¬ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        # ì§€ì—­ x ì—…ì¢… ì¡°í•© ìƒì„±
        combinations = []
        for region in sorted(X['district_code'].unique()):
            for business in sorted(X['business_type_code'].unique()):
                mask = (X['district_code'] == region) & (X['business_type_code'] == business)
                sample_count = mask.sum()
                
                if sample_count >= 10:  # ìµœì†Œ ìƒ˜í”Œ ìˆ˜
                    combinations.append((region, business, sample_count))
        
        # ìƒ˜í”Œ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ ëª¨ë¸ë§Œ ì„ íƒ
        combinations.sort(key=lambda x: x[2], reverse=True)
        combinations = combinations[:max_models]
        
        logger.info(f"   ì„ íƒëœ ì¡°í•©: {len(combinations)}ê°œ")
        
        def train_single_local_model(combo):
            """ë‹¨ì¼ ë¡œì»¬ ëª¨ë¸ í›ˆë ¨ (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
            region, business, sample_count = combo
            
            try:
                # ë°ì´í„° í•„í„°ë§
                mask = (X['district_code'] == region) & (X['business_type_code'] == business)
                X_local = X[mask]
                y_local = y[mask]
                
                # ë°ì´í„° ë¶„í• 
                X_train, X_test, y_train, y_test = train_test_split(
                    X_local, y_local, test_size=0.2, random_state=42
                )
                
                # ë¡œì»¬ ëª¨ë¸ (ê°„ë‹¨í•œ ëª¨ë¸ ì‚¬ìš©)
                model = Ridge(alpha=10.0)  # ì •ê·œí™”ë¥¼ ë” ê°•í•˜ê²Œ
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                # ì„±ëŠ¥ í‰ê°€
                mse = mean_squared_error(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                
                # ëª¨ë¸ ì €ì¥
                model_path = self.models_dir / f'local_model_{region}_{business}.joblib'
                joblib.dump(model, model_path)
                
                return {
                    'model_type': 'local',
                    'region_id': region,
                    'business_id': business,
                    'model_path': str(model_path),
                    'performance': {
                        'mse': mse,
                        'mae': mae,
                        'r2': r2,
                        'rmse': np.sqrt(mse)
                    },
                    'training_samples': len(X_train),
                    'test_samples': len(X_test),
                    'total_samples': sample_count
                }
                
            except Exception as e:
                return {
                    'error': str(e),
                    'region_id': region,
                    'business_id': business
                }
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¡œì»¬ ëª¨ë¸ í›ˆë ¨
        successful_models = 0
        failed_models = 0
        
        with ThreadPoolExecutor(max_workers=4) as executor:
            future_to_combo = {executor.submit(train_single_local_model, combo): combo for combo in combinations}
            
            for future in as_completed(future_to_combo):
                combo = future_to_combo[future]
                region, business, _ = combo
                
                try:
                    result = future.result()
                    
                    if 'error' in result:
                        logger.warning(f"   ì§€ì—­ {region}, ì—…ì¢… {business}: {result['error']}")
                        failed_models += 1
                        self.training_results['errors'].append(f"local_{region}_{business}: {result['error']}")
                    else:
                        local_results[f'local_{region}_{business}'] = result
                        successful_models += 1
                        
                        if successful_models % 5 == 0:  # 5ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
                            logger.info(f"   ì§„í–‰ë¥ : {successful_models}/{len(combinations)} ì™„ë£Œ...")
                
                except Exception as e:
                    logger.error(f"   ì§€ì—­ {region}, ì—…ì¢… {business} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    failed_models += 1
        
        self.model_performance.update(local_results)
        self.training_results['models_trained'] += successful_models
        self.training_results['models_failed'] += failed_models
        
        logger.info(f"âœ… ë¡œì»¬ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ (ì„±ê³µ: {successful_models}, ì‹¤íŒ¨: {failed_models})")
        
        return local_results
    
    def generate_training_report(self) -> str:
        """í›ˆë ¨ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        end_time = datetime.now()
        total_time = (end_time - self.training_results['start_time']).total_seconds()
        
        # ì„±ëŠ¥ ìš”ì•½ ê³„ì‚°
        all_r2_scores = []
        model_type_counts = {'global': 0, 'regional': 0, 'local': 0}
        
        for model_key, model_info in self.model_performance.items():
            if 'performance' in model_info:
                r2 = model_info['performance']['r2']
                all_r2_scores.append(r2)
                
                model_type = model_info['model_type']
                model_type_counts[model_type] += 1
        
        avg_r2 = np.mean(all_r2_scores) if all_r2_scores else 0
        max_r2 = max(all_r2_scores) if all_r2_scores else 0
        min_r2 = min(all_r2_scores) if all_r2_scores else 0
        
        total_models = self.training_results['models_trained'] + self.training_results['models_failed']
        success_rate = (self.training_results['models_trained'] / total_models * 100) if total_models > 0 else 0
        
        report = f"""
ğŸ¢ ì„œìš¸ ì‹œì¥ ìœ„í—˜ë„ ML ì‹œìŠ¤í…œ - ëª¨ë¸ í›ˆë ¨ ë³´ê³ ì„œ
{'='*60}

ğŸ“Š í›ˆë ¨ ê²°ê³¼ ìš”ì•½:
  â€¢ ì´ í›ˆë ¨ ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)
  â€¢ ì„±ê³µí•œ ëª¨ë¸: {self.training_results['models_trained']}ê°œ
  â€¢ ì‹¤íŒ¨í•œ ëª¨ë¸: {self.training_results['models_failed']}ê°œ
  â€¢ ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}%

ğŸ”§ ëª¨ë¸ ìœ í˜•ë³„ í˜„í™©:
  â€¢ ê¸€ë¡œë²Œ ëª¨ë¸: {model_type_counts['global']}ê°œ
  â€¢ ì§€ì—­ ëª¨ë¸: {model_type_counts['regional']}ê°œ  
  â€¢ ë¡œì»¬ ëª¨ë¸: {model_type_counts['local']}ê°œ

ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:
  â€¢ í‰ê·  R2 ì ìˆ˜: {avg_r2:.3f}
  â€¢ ìµœê³  R2 ì ìˆ˜: {max_r2:.3f}
  â€¢ ìµœì € R2 ì ìˆ˜: {min_r2:.3f}

â° ì™„ë£Œ ì‹œê°: {end_time.strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        if self.training_results['errors']:
            report += f"\nâŒ ì˜¤ë¥˜ ëª©ë¡ ({len(self.training_results['errors'])}ê°œ):\n"
            for error in self.training_results['errors'][:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                report += f"  â€¢ {error}\n"
            
            if len(self.training_results['errors']) > 10:
                report += f"  â€¢ ... ë° {len(self.training_results['errors'])-10}ê°œ ì¶”ê°€ ì˜¤ë¥˜\n"
        
        # ë³´ê³ ì„œ ì €ì¥
        report_path = Path("training_report.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        # ì„±ëŠ¥ ë°ì´í„° JSON ì €ì¥
        performance_path = Path("model_performance.json")
        with open(performance_path, 'w', encoding='utf-8') as f:
            # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            serializable_results = self.training_results.copy()
            serializable_results['start_time'] = self.training_results['start_time'].isoformat()
            serializable_results['end_time'] = end_time.isoformat()
            serializable_results['model_performance'] = self.model_performance
            
            json.dump(serializable_results, f, indent=2, ensure_ascii=False, default=str)
        
        return report
    
    def run_full_training(self):
        """ì „ì²´ ëª¨ë¸ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ì„œìš¸ ì‹œì¥ ìœ„í—˜ë„ ML ì‹œìŠ¤í…œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        logger.info("="*60)
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            df = self.load_training_data()
            
            # 2. íŠ¹ì„± ì¤€ë¹„
            X, y = self.prepare_features(df)
            
            # 3. ê¸€ë¡œë²Œ ëª¨ë¸ í›ˆë ¨
            global_result = self.train_global_model(X, y)
            
            # 4. ì§€ì—­ ëª¨ë¸ í›ˆë ¨
            regional_results = self.train_regional_models(X, y)
            
            # 5. ë¡œì»¬ ëª¨ë¸ í›ˆë ¨ (ìµœëŒ€ 20ê°œ)
            local_results = self.train_local_models(X, y, max_models=20)
            
            # 6. ë³´ê³ ì„œ ìƒì„±
            report = self.generate_training_report()
            logger.info("\n" + report)
            
            total_models = len(regional_results) + len(local_results) + (1 if global_result else 0)
            logger.info(f"ğŸ‰ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! ì´ {total_models}ê°œ ëª¨ë¸ ìƒì„±")
            
            return {
                'global': global_result,
                'regional': regional_results,
                'local': local_results,
                'total_models': total_models
            }
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ëª¨ë¸ í›ˆë ¨ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            self.training_results['errors'].append(f"fatal: {str(e)}")
            raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    trainer = SeoulModelTrainer()
    results = trainer.run_full_training()
    
    print(f"\nğŸ¯ í›ˆë ¨ ê²°ê³¼:")
    print(f"  ê¸€ë¡œë²Œ ëª¨ë¸: {'âœ…' if results['global'] else 'âŒ'}")
    print(f"  ì§€ì—­ ëª¨ë¸: {len(results['regional'])}ê°œ")
    print(f"  ë¡œì»¬ ëª¨ë¸: {len(results['local'])}ê°œ")
    print(f"  ì´ ëª¨ë¸: {results['total_models']}ê°œ")
    
    return 0


if __name__ == "__main__":
    exit(main())